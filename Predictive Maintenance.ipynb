{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code by James A White"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped Validation Set\n",
    "In the interest of keeping this analysis fairly easy to follow the validation set has been excluded in favour of a test set only. It is standard practice to have a train, validation and test set if there are enough available data, as this generally gives a more reliable estimate of how the algorithm will perform in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is by no means an exaustive analysis and is only a rough representation of what can be done for this type of problem. There are certain obvious steps which have not been included some of which are outlined near the end of this notebook. Although this notebook outlines the process for facilitating predictive maintenance, similar logic can be used for other time series regression or even classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "import catboost\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['unit_number', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i+1) for i in range(0,21)]\n",
    "col_names = index_names + setting_names + sensor_names\n",
    "directory = r'C:\\Users\\ecf\\Documents\\predictive_maintenance'\n",
    "train_df = pd.read_csv(directory+r'\\train_FD003.txt', \n",
    "                    sep='\\s+', \n",
    "                    header=None,\n",
    "                    index_col=False,\n",
    "                    names=col_names)\n",
    "train = train_df.copy()\n",
    "\n",
    "test_df = pd.read_csv(directory+r'\\test_FD003.txt', \n",
    "                    sep='\\s+', \n",
    "                    header=None,\n",
    "                    index_col=False,\n",
    "                    names=col_names)\n",
    "test = test_df.copy()\n",
    "\n",
    "y_test = pd.read_csv(directory+r'\\RUL_FD003.txt', \n",
    "                     sep='\\s+', \n",
    "                     header=None,\n",
    "                     index_col=False,\n",
    "                     names=['RUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,'s_1':].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_remaining_useful_life(df):\n",
    "\n",
    "    grouped_by_unit = df.groupby(by='unit_number')\n",
    "    max_cycle = grouped_by_unit['time_cycles'].max()\n",
    "    \n",
    "    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_number', right_index=True)\n",
    "    \n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life = result_frame[\"max_cycle\"] - result_frame['time_cycles']\n",
    "    result_frame[\"RUL\"] = remaining_useful_life\n",
    "    \n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n",
    "    return result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_remaining_useful_life(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ruls = train.groupby('unit_number').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ruls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ruls['RUL'].hist(bins=20)\n",
    "plt.xlabel('RUL')\n",
    "plt.ylabel('frequency')\n",
    "print(max_ruls['RUL'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of RUL\n",
    "It looks log-normal with the majority of the max RUL data in the 150-250 range. One of a few insights from this is that if there many were more simulations we could be fairly confident that the RUL would never be greater than 550 cycles. This information could be used to clip predictions at a particular maximum which may make the algorithm more reliable/accurate in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Sensor Signals\n",
    "Now to look at what the sensor signals look like, this will help in determining \"good\" and \"bad\" sensors or sensors that contain a lot of information vs ones that don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(df, signal_name):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for i in df['unit_number'].unique():\n",
    "        if (i % 10 == 0):  \n",
    "            plt.plot('RUL', signal_name, \n",
    "                     data=df[df['unit_number']==i])\n",
    "    plt.xlim(250, 0)  # reverse the x-axis so RUL counts down to zero\n",
    "    plt.xticks(np.arange(0, 300, 25))\n",
    "    plt.ylabel(signal_name)\n",
    "    plt.xlabel('Remaining Useful Life')\n",
    "    plt.show()\n",
    "\n",
    "def plot_smooth_signal(df, smothed_signal):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    for i in df['unit_number'].unique():\n",
    "        if i == 10:#(i % 10 == 0):  \n",
    "            plt.plot(df[df['unit_number']==i]['RUL'], smothed_signal)\n",
    "    plt.xlim(250, 0)  # reverse the x-axis so RUL counts down to zero\n",
    "    plt.xticks(np.arange(0, 300, 25))\n",
    "    plt.ylabel(signal_name)\n",
    "    plt.xlabel('Remaining Useful Life')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in ['s_1',\n",
    "               's_2',\n",
    "               's_3',\n",
    "               's_4',\n",
    "               's_5',\n",
    "               's_6',\n",
    "               's_7',\n",
    "               's_8',\n",
    "               's_9',\n",
    "               's_10',\n",
    "               's_11',\n",
    "               's_12',\n",
    "               's_13',\n",
    "               's_14',\n",
    "               's_15',\n",
    "               's_16',\n",
    "               's_17',\n",
    "               's_18',\n",
    "               's_19',\n",
    "               's_20',\n",
    "               's_21']:\n",
    "    try:\n",
    "        plot_signal(train, sensor)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Sensor Analysis\n",
    "From looking at the above it seems as though sensors 1, 5, 16, 18 and 19 have very little to no information to determine ot help predict the RUL. These will be removed before prediction below to help the speed and generalisation of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "# drop unwanted columns and split target variable from training set\n",
    "drop_sensors = ['s_1','s_5','s_16','s_18','s_19']\n",
    "drop_labels = index_names+setting_names+drop_sensors\n",
    "remaining_sensors = ['s_2', 's_3', 's_4', 's_6', 's_7', 's_8', 's_9', 's_10',\n",
    "       's_11', 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "\n",
    "X_train = train.drop(drop_labels, axis=1)\n",
    "y_train = X_train.pop('RUL')\n",
    "\n",
    "X_test = test.groupby('unit_number').last().reset_index().drop(drop_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the evalution function for the RMSE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Training\n",
    "Below a few algorithms are tested to see which will perform best on the test set, this is just a small list and more algorithms should be tested to achieve the best results. There has been no feature scaling because we are using tree based algorithms only, however, this is usually a necessary step to test other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = xgb.predict(X_train)\n",
    "evaluate(y_train, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = xgb.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb = catboost.CatBoostRegressor(verbose=False, random_state=42)\n",
    "catb.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = catb.predict(X_train)\n",
    "evaluate(y_train, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = catb.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=\"sqrt\", random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = rf.predict(X_train)\n",
    "evaluate(y_train, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = rf.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Results\n",
    "It is always important to visualise the predictions vs the results as a single metric doesn't always tell the whole story. For example most predictions may be good but there may be one prediction that is a large outlier that would be unacceptable to put into production for particular applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_test, y_hat_test):\n",
    "    width = 0.8\n",
    "\n",
    "    actuals = [int(x) for x in y_test.values]\n",
    "    predictions = list(y_hat_test)\n",
    "\n",
    "    indices = np.arange(len(y_hat_test))\n",
    "\n",
    "    plt.figure(figsize=(60,20))\n",
    "\n",
    "    plt.bar(indices, actuals, width=width, \n",
    "            color='b', label='Actual RUL')\n",
    "    plt.bar([i for i in indices], predictions, \n",
    "            width=0.5*width, color='r', alpha=0.7, label='Predicted RUL')\n",
    "\n",
    "    plt.legend(prop={'size': 30})\n",
    "    plt.tick_params(labelsize=30)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUL Clipping\n",
    "\n",
    "Apply RUL clipping making the max RUL value 115, this helps the predictions as we will see below. It makes sense because the sensor values with a 200 RUL are quite similar to those with a 115 RUL so the algorithm will not be able to distinguish between these well. Also the maximum RUL in the test set is 115 which is about the point where the sensors really start to change (referring to the line graphs above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_sensors = ['s_1','s_5','s_16','s_18','s_19']\n",
    "drop_labels = index_names+setting_names+drop_sensors\n",
    "remaining_sensors = ['s_2', 's_3', 's_4', 's_6', 's_7', 's_8', 's_9', 's_10',\n",
    "       's_11', 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "\n",
    "X_train = train.drop(drop_labels, axis=1)\n",
    "y_train = X_train.pop('RUL')\n",
    "y_train_clipped = y_train.clip(upper=115)  # apply RUL clipping\n",
    "\n",
    "X_test = test.groupby('unit_number').last().reset_index().drop(drop_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=\"sqrt\", random_state=42)\n",
    "rf.fit(X_train, y_train_clipped)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = rf.predict(X_train)\n",
    "evaluate(y_train_clipped, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = rf.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A big improvement, more than halved the RMSE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.8\n",
    "\n",
    "actuals = [int(x) for x in y_test.values]\n",
    "predictions = list(y_hat_test)\n",
    "\n",
    "indices = np.arange(len(y_hat_test))\n",
    "\n",
    "plt.figure(figsize=(60,20))\n",
    "\n",
    "plt.bar(indices, actuals, width=width, \n",
    "        color='b', label='Actual RUL')\n",
    "plt.bar([i for i in indices], predictions, \n",
    "        width=0.5*width, color='r', alpha=0.7, label='Predicted RUL')\n",
    "\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.tick_params(labelsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Smoothing\n",
    "Visualising the signals (line graphs above) we can see that the signals are quite noisy. Another thing we can try to improve the prediction results is to remove some of the noise. To help remove the noise we can implement various filters, I've chosen to use the Savitzky-Golay filter. This basically fits regressions to subsets of the data and has the option to differentiate the data as well. It works quite well for this particular case but may not be the best filter. Again similar to the algorithm selection above many filters should be tested to achieve the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal smoothing function\n",
    "def apply_scipy_filter(df, scipy_filter):\n",
    "    for unit in df['unit_number'].unique():\n",
    "        for sensor in df.loc[:,'s_1':]:\n",
    "            if sensor != 'RUL':\n",
    "    \n",
    "                df.loc[df['unit_number']==unit, sensor] = scipy_filter(df.loc[df['unit_number']==unit, sensor],\n",
    "                                                                              window_length=19, \n",
    "                                                                              polyorder=1,\n",
    "                                                                              deriv=0,\n",
    "                                                                              mode='interp') \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Application\n",
    "After some quick testing the best results were achieved by applying the filter 3 times to the data. Again, there may be better combinations or ways of filtering the data but only a few different combinations were explored here. Certain optimisation algorithms can help in the selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = apply_scipy_filter(train, ss.savgol_filter)\n",
    "train = apply_scipy_filter(train, ss.savgol_filter)\n",
    "train = apply_scipy_filter(train, ss.savgol_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = apply_scipy_filter(test, ss.savgol_filter)\n",
    "test = apply_scipy_filter(test, ss.savgol_filter)\n",
    "test = apply_scipy_filter(test, ss.savgol_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Sensor Signals\n",
    "We can see from the graphs below that the filters have worked quite well removing a lot of the noise in the signal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in ['s_1',\n",
    "               's_2',\n",
    "               's_3',\n",
    "               's_4',\n",
    "               's_5',\n",
    "               's_6',\n",
    "               's_7',\n",
    "               's_8',\n",
    "               's_9',\n",
    "               's_10',\n",
    "               's_11',\n",
    "               's_12',\n",
    "               's_13',\n",
    "               's_14',\n",
    "               's_15',\n",
    "               's_16',\n",
    "               's_17',\n",
    "               's_18',\n",
    "               's_19',\n",
    "               's_20',\n",
    "               's_21']:\n",
    "    try:\n",
    "        plot_signal(train, sensor)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "# drop unwanted columns and split target variable from training set\n",
    "drop_sensors = ['s_1','s_5','s_16','s_18','s_19']  # s_6 and s_10 get the benefit of the doubt\n",
    "drop_labels = index_names+setting_names+drop_sensors\n",
    "remaining_sensors = ['s_2', 's_3', 's_4', 's_6', 's_7', 's_8', 's_9', 's_10',\n",
    "       's_11', 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "\n",
    "X_train = train.drop(drop_labels, axis=1)\n",
    "y_train = X_train.pop('RUL')\n",
    "y_train_clipped = y_train.clip(upper=125)  # apply RUL clipping\n",
    "\n",
    "# Since the true RUL values for the test set are only provided for the last time cycle of each engine, \n",
    "# the test set is subsetted to represent the same\n",
    "X_test = test.groupby('unit_number').last().reset_index().drop(drop_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=\"sqrt\", random_state=42)\n",
    "rf.fit(X_train, y_train_clipped)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = rf.predict(X_train)\n",
    "evaluate(y_train_clipped, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = rf.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Improvement\n",
    "Here we get another improvement although quite a bit more modest than the RUL clipping it still has lowered the RMSE a significant amount and improved the R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Bayesian Optimisation\n",
    "Algorithm not included - contact 4CDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params found using Bayesian Optimisation\n",
    "rf = RandomForestRegressor(n_estimators = 32,\n",
    "                           max_depth = 22,\n",
    "                           min_samples_split = 6,\n",
    "                           max_features = 1,\n",
    "                           min_samples_leaf = 8,\n",
    "                           random_state = 42)\n",
    "rf.fit(X_train, y_train_clipped)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = rf.predict(X_train)\n",
    "evaluate(y_train_clipped, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = rf.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: XGBoost with optimization\n",
    "Algorithm not included - contact 4CDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params found using Bayesian Optimisation\n",
    "xgb = xgboost.XGBRegressor(n_estimators=32, \n",
    "                           max_depth=22,\n",
    "                           learning_rate=0.287874962131598,\n",
    "                           reg_lambda=5,\n",
    "                           gamma=0.4510565094063483,\n",
    "                           random_state=42)\n",
    "xgb.fit(X_train, y_train_clipped)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = xgb.predict(X_train)\n",
    "evaluate(y_train_clipped, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = xgb.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
